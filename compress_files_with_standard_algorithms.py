""" Needs Code Review. Large portions are autogenerated. https://chatgpt.com/share/672b912c-5c74-800e-8062-cee96ac9cc28
"""
import gzip
import bz2
import lzma
import zipfile
import pyzstd
import logging
from pathlib import Path
import argparse
from typing import Optional
import time
from tqdm import tqdm
from tabulate import tabulate
import shutil


# Set up logging configuration
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


# Constants for supported decompression extensions and their corresponding libraries
DECOMPRESSION_HANDLERS = {
    ".gz": gzip.open,
    ".bz2": bz2.open,
    ".xz": lzma.open,
    ".zip": zipfile.ZipFile,
    ".zst": pyzstd.decompress_stream,
}
# Constants for supported extensions and their corresponding libraries
COMPRESSION_HANDLERS = {
    ".gz": gzip.open,
    ".bz2": bz2.open,
    ".xz": lzma.open,
    ".zip": zipfile.ZipFile,
    ".zst": pyzstd.compress_stream,
}

class UnsupportedCompressionFormatError(Exception):
    """Exception raised for unsupported compression formats."""
    pass


def log_decompression_success(input_file: Path, output_file: Path, method: str) -> None:
    """Helper function to log a success message after decompression."""
    logging.debug(f"Decompressed {input_file} to {output_file} using {method}.")

def decompress_file(input_file: Path, output_path: Path) -> bool:
    """Decompress a single file based on its extension.
    
    Parameters:
    - input_file: Path to the compressed file.
    - output_path: Path to the output directory or file where decompressed content will be stored.
    
    Returns:
    - bool: True if decompression succeeds, False otherwise.
    
    Supported formats are .gz, .bz2, .xz, .zip.
    """
    if not input_file.is_file():
        raise FileNotFoundError(f"The input path '{input_file}' is not a valid file.")

    ext = input_file.suffix.lower()
    handler = DECOMPRESSION_HANDLERS.get(ext)

    if handler is None:
        raise UnsupportedCompressionFormatError(
            f"Unsupported decompression format '{ext}'. Supported formats are: {', '.join(DECOMPRESSION_HANDLERS.keys())}."
        )

    try:
        if ext == ".zip":
            with handler(input_file, "r") as zip_in:
                zip_in.extractall(output_path)
            log_decompression_success(input_file, output_path, "zip")
        elif ext == ".zst":
            # Ensure output path is a file path, not a directory
            if output_path.is_dir():
                output_file = output_path / input_file.stem
            else:
                output_file = output_path
            with open(input_file, "rb") as f_in:
                with open(output_file, "wb") as f_out:
                    handler(f_in, f_out)

        else:
            with handler(input_file, "rb") as f_in:
                # Ensure output path is a file path, not a directory
                if output_path.is_dir():
                    output_file = output_path / input_file.stem
                else:
                    output_file = output_path
                
                with open(output_file, "wb") as f_out:
                    f_out.write(f_in.read())
            log_decompression_success(input_file, output_file, ext[1:])
        return True

    except FileNotFoundError as e:
        logging.exception(e)
    except IsADirectoryError as e:
        logging.exception(e)
    except OSError as e:
        logging.exception(e)
    except IOError as e:
        logging.exception(e)
    
    return False



def log_compression_success(input_file: Path, output_file: Path, method: str) -> None:
    """Helper function to log a success message after compression."""
    logging.debug(f"Compressed {input_file} to {output_file} using {method}.")

def compress_file(input_file: Path, output_file: Path, compression_level: int = None) -> bool:
    """Compress a single file based on its output extension."""
    if not input_file.is_file():
        raise FileNotFoundError(f"The input path '{input_file}' is not a valid file.")

    ext = output_file.suffix.lower()
    handler = COMPRESSION_HANDLERS.get(ext)

    if handler is None:
        raise UnsupportedCompressionFormatError(
            f"Unsupported compression format '{ext}'. Supported formats are: {', '.join(COMPRESSION_HANDLERS.keys())}."
        )

    try:
        with open(input_file, "rb") as f_in:
            if ext == ".zip":
                with handler(output_file, "w", zipfile.ZIP_DEFLATED) as zip_out:
                    zip_out.write(input_file, arcname=input_file.name)
                log_compression_success(input_file, output_file, "zip")
            elif ext == ".zst":
                with open(input_file, "rb") as f_in:
                    with open(output_file, "wb") as f_out:
                        handler(f_in, f_out)
            else:
                open_kwargs = {"mode": "wb"}
                if compression_level is not None:
                    open_kwargs["compresslevel" if ext == ".gz" or ext ==".bz2" else "preset"] = compression_level
                with handler(output_file, **open_kwargs) as f_out:
                    f_out.write(f_in.read())
                log_compression_success(input_file, output_file, ext[1:])
            return True

    except FileNotFoundError as e:
        logging.exception(e)
    except IsADirectoryError as e:
        logging.exception(e)
    except OSError as e:
        #logging.exception(e)
        pass
    except IOError as e:
        logging.exception(e)
        # raise IOError(f"An error occurred while writing to '{output_file}': {e}")
    return False

def compress_files_recursively_in_place(input_dir: Path, compression_type:str=".gz", compression_level: Optional[int] = None, remove_source: bool = False):
    """
    Recursively compresses each file in a directory and its subdirectories, saving compressed files alongside originals.
    Optionally removes the original file after compression if `remove_source` is True.
    """
    if not input_dir.is_dir():
        logging.error(f"The input path '{input_dir}' is not a valid directory.")
        return
    
    # Iterate over all files recursively in the directory and subdirectories
    for item in input_dir.rglob("*"):
        if item.is_file():
            # Determine the output compressed file path
            output_file = item.with_suffix(item.suffix + compression_type)
            
            try:
                # Compress the file using the specified compression level
                compress_file(item, output_file, compression_level)
                
                # Remove the original file if the flag is set
                if remove_source:
                    item.unlink()
                    logging.debug(f"Original file '{item}' removed after compression.")
                    
            except UnsupportedCompressionFormatError as e:
                logging.error(e)
            except Exception as e:
                logging.error(f"Failed to compress '{item}': {e}")


def compress_files_to_new_folder(input_dir: Path, output_dir: Path, compression_type:str=".gz", compression_level: Optional[int] = None):
    """
    Compresses each file in the input directory (recursively) to the specified output directory,
    preserving the directory structure.
    
    Parameters:
    - input_dir: Path to the directory containing files to compress.
    - output_dir: Path to the directory where compressed files will be saved.
    - compression_level: Optional; compression level to use if supported (e.g., 0-9 for gzip).
    """
    # Ensure the output directory exists
    output_dir.mkdir(parents=True, exist_ok=True)
    paths_to_compress = [path for path in input_dir.rglob("*") if path.is_file()]
    compressed_successfully = 0
    for item in tqdm(paths_to_compress):
        if item.is_file():
            # Determine the relative path within the output directory to maintain structure
            relative_path = item.relative_to(input_dir)
            compressed_path = output_dir / relative_path.with_suffix(relative_path.suffix + compression_type)

            # Ensure parent directories exist in the output directory structure
            compressed_path.parent.mkdir(parents=True, exist_ok=True)

            try:
                # Compress the file
                compression_successful = compress_file(item, compressed_path, compression_level)
                if compression_successful:
                    compressed_successfully = compressed_successfully + 1
                
                # logging.info(f"Compressed '{item}' to '{compressed_path}'")
            except UnsupportedCompressionFormatError as e:
                logging.error(e)
            except Exception as e:
                logging.error(f"{type(e)}, Failed to compress '{item}': {e}")
    logging.info(f"{compressed_successfully}/{len(paths_to_compress)} files compressed")


def decompress_files_from_folder(compressed_dir: Path, output_dir: Path) -> None:
    """
    Decompresses files in a folder based on their extensions.
    
    Parameters:
    - compressed_dir (Path): Directory containing compressed files to decompress.
    - output_dir (Path): Directory where decompressed files will be saved.
    """
    for compressed_file in compressed_dir.rglob("*"):
        if compressed_file.suffix in COMPRESSION_HANDLERS:
            output_path = output_dir / compressed_file.stem  # Decompress to original filename without compression extension
            decompress_file(compressed_file, output_path)
            logging.debug(f"Decompressed {compressed_file} to {output_path}")


def benchmark_compression_schemes(input_dir: Path, output_dir: Path, compression_level: int = 5, results_file: Path = None) -> None:
    """
    Benchmarks various compression schemes by compressing and decompressing files in `input_dir`, 
    calculating time and compression ratio, and logging results in a table.

    Parameters:
    - input_dir (Path): Path to the directory containing files to compress.
    - output_dir (Path): Path to the directory where compressed files will be saved.
    - compression_level (int): Compression level to use for applicable formats.
    - results_file (Path): Optional path to save the benchmark results table.
    """
    # Ensure output_dir exists
    output_dir.mkdir(parents=True, exist_ok=True)

    # Prepare results storage
    results = []
    input_dir_files = [f for f in input_dir.rglob("*") if f.is_file()]
    
    for ext, handler in COMPRESSION_HANDLERS.items():
        # Setup directories
        subdir = output_dir / ext[1:]  # Remove the leading '.' from extension
        subdir.mkdir(parents=True, exist_ok=True)

        # Compression Benchmark
        logging.info(f"Starting compression with {ext} to {subdir}")
        start_compress = time.perf_counter()
        compress_files_to_new_folder(input_dir, subdir, compression_type=ext, compression_level=compression_level)
        compress_duration = time.perf_counter() - start_compress

        # input files 
        

        # Calculate total compressed size
        compressed_size = sum(f.stat().st_size for f in subdir.rglob("*") if f.is_file())
        original_size = sum(f.stat().st_size for f in input_dir_files)
        compression_ratio = original_size / compressed_size if compressed_size > 0 else float("inf")

        logging.info(f"Compressed size: {compressed_size}, original_size: {original_size}")

        logging.info(f"Compression with {ext} completed in {compress_duration:.2f} seconds.")
        
        # Decompression Benchmark
        decompression_dir = subdir / "decompressed"
        decompression_dir.mkdir(exist_ok=True)

        logging.info(f"Starting decompression with {ext} from {subdir} to {decompression_dir}")
        start_decompress = time.perf_counter()
        decompress_files_from_folder(subdir, decompression_dir)
        decompress_duration = time.perf_counter() - start_decompress

        logging.info(f"Decompression with {ext} completed in {decompress_duration:.2f} seconds.")
        
        # Save results
        results.append([
            ext, 
            f"{original_size / (1024 ** 2):.2f} MB", 
            f"{compressed_size / (1024 ** 2):.2f} MB", 
            f"{compression_ratio:.2f}", 
            f"{compress_duration:.2f} s", 
            f"{compress_duration/len(input_dir_files):.2f} s", 
            f"{decompress_duration:.2f} s",
            f"{decompress_duration/len(input_dir_files):.2f} s",
        ])

        # Cleanup decompression directory after timing
        shutil.rmtree(decompression_dir)

    # Display and save results table
    headers = ["Format", 
    "Original Size", 
    "Compressed Size", 
    "Compression Ratio", 
    "Compression Time", 
    "Compression Time (avg)", 
    "Decompression Time", 
    "Decompression Time (avg)"
    ]
    table = tabulate(results, headers=headers, tablefmt="pretty")
    print(f"Results of benchmark on {len(input_dir_files)} files")
    print(table)


    if results_file:
        with open(results_file, "w") as f:
            f.write(table)
        logging.info(f"Benchmark results written to {results_file}")

def main():
    parser = argparse.ArgumentParser(description="Compress files in a directory with flexible output options.")
    parser.add_argument("input_dir", type=Path, help="Path to the directory containing files to compress.")
    parser.add_argument(
        "--output_mode",
        choices=["alongside", "in_place", "output_dir", "benchmark"],
        default="in_place",
        help="Choose where compressed files are saved: 'alongside' originals, 'in_place' (replaces originals), or to a specified 'output_dir'.",
    )
    parser.add_argument(
        "--output_dir",
        type=Path,
        help="Specify the output directory if using 'output_dir' mode. Directory will be created if it does not exist",
    )
    parser.add_argument(
        "--compression_type",
        type=str,
        choices=list(COMPRESSION_HANDLERS.keys()),
        help=f"Specify compression type.",
    )
    parser.add_argument(
        "--compression_level",
        type=int,
        choices=range(0, 10),
        default=5,
        help="Compression level (0-9) for formats that support it.",
    )    
    
    

    args = parser.parse_args()

    # Handle output mode logic
    if args.output_mode == "in_place":
        compress_files_recursively_in_place(args.input_dir, 
        compression_type=args.compression_type, 
        compression_level=args.compression_level, 
        remove_source=True)
    elif args.output_mode == "alongside":
        # def compress_files_recursively_in_place(input_dir: Path, compression_type:str=".gz", compression_level: Optional[int] = None, remove_source: bool = False):
        compress_files_recursively_in_place(args.input_dir,
        compression_type=args.compression_type,  
        compression_level=args.compression_level, 
        remove_source=False)
    elif args.output_mode == "benchmark":
        output_dir = Path.cwd() / "benchmarking"
        if args.output_dir:
            output_dir = args.output_dir
        benchmark_compression_schemes(args.input_dir, output_dir)
    elif args.output_mode == "output_dir":
        # Verify that output_dir is provided and is a directory
        if not args.output_dir:
            parser.error("The --output_dir argument is required when using 'output_dir' mode.")
        compress_files_to_new_folder(args.input_dir, 
        args.output_dir, 
        args.compression_type,
        args.compression_level)


# Example usage:
# python compress_script.py /path/to/input_dir --output_mode output_dir --output_dir /path/to/output_dir --compression_level 5

if __name__ == "__main__":
    main()
